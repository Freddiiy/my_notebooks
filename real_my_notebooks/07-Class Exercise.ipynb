{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Week 7: Web scraping, BS4, Selenium and Regexp\n",
    "### Part 1\n",
    "##### 30 min\n",
    "1. Make a request to: `https://en.wikipedia.org/wiki/Alan_Turing` and print out the responses .text property\n",
    "2. Find and print the title of the response page\n",
    "3. Find and print content of the first p tag that has content.\n",
    "4. Find and print all content from the TOC\n",
    "##### 20 min\n",
    "5. Create a dictionary from the TOC links like: {'first link':'#this_is_the_first_link}\n",
    "### Pause\n",
    "##### 40 min\n",
    "6. Create a function that can take a word and look for it in the dictionary keys and then return the content from the first link that matches. Return the next p elements until next headline (h3 element).\n",
    "7. Make it into a cli program.\n",
    "\n",
    "### Pause\n",
    "\n",
    "### Part 2\n",
    "##### 40 min\n",
    "1. Using regex find out how many times 'Turing' is used in the article\n",
    "9. Regex: Find all the sentences that has a year in them (sentense defined by: starting at \\n or dot or comma and ending at dot or comma.\n",
    "\n",
    "### Part 3\n",
    "##### 40 min\n",
    "1. Use selenium to go to amazon.com and search for `Pet Shower Cap - Waterproof Reusable Bath Ear Covers`\n",
    "2. Print how many products were found\n",
    "3. Find the cheapest and the most expensive product from the list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Early life and education': '#Early_life_and_education', 'Career and research': '#Career_and_research', 'Personal life': '#Personal_life', 'Legacy': '#Legacy', 'Notes and references': '#Notes_and_references', 'Further reading': '#Further_reading', 'External links': '#External_links', 'Family': '#Family', 'School': '#School', 'Christopher Morcom': '#Christopher_Morcom', 'University and work on computability': '#University_and_work_on_computability', 'Cryptanalysis': '#Cryptanalysis', 'Bombe': '#Bombe', 'Hut 8 and the naval Enigma': '#Hut_8_and_the_naval_Enigma', 'Turingery': '#Turingery', 'Delilah': '#Delilah', 'Early computers and the Turing test': '#Early_computers_and_the_Turing_test', 'Pattern formation and mathematical biology': '#Pattern_formation_and_mathematical_biology', 'Engagement': '#Engagement', 'Homosexuality and indecency conviction': '#Homosexuality_and_indecency_conviction', 'Treasure': '#Treasure', 'Death': '#Death', 'Government apology and pardon': '#Government_apology_and_pardon', 'Awards, honours, and tributes': '#Awards,_honours,_and_tributes', 'Centenary celebrations': '#Centenary_celebrations', 'Notes': '#Notes', 'References': '#References', 'Sources': '#Sources', 'Articles': '#Articles', 'Books': '#Books'}\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "url = \"https://en.wikipedia.org/wiki/Alan_Turing\"\n",
    "res = requests.get(url)\n",
    "soup = bs4.BeautifulSoup(res.text)\n",
    "\n",
    "outer_toc = soup.select('.toc > ul > li')\n",
    "inner_toc = soup.select('.toc > ul > li > ul > li')\n",
    "\n",
    "toc_dict = {}\n",
    "for el in outer_toc:\n",
    "    text = el.getText()\n",
    "    a = el.select('a')\n",
    "    val = a[0].get('href')\n",
    "    key = text.split(\" \", 1)[1]\n",
    "    key = key.split(\"\\n\")[0]\n",
    "    toc_dict[key] = val\n",
    "\n",
    "for el in inner_toc:\n",
    "    text = el.getText()\n",
    "    a = el.select('a')\n",
    "    val = a[0].get('href')\n",
    "    key = text.split(\" \", 1)[1]\n",
    "    key = key.split(\"\\n\")[0]\n",
    "    toc_dict[key] = val\n",
    "\n",
    "print(toc_dict)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Create a function that can take a word and look for it in the dictionary keys and then return the content from the first link that matches. Return the next p elements until next headline (h3 element).\n",
    "7. Make it into a cli program."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2499773424.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Input \u001B[0;32mIn [6]\u001B[0;36m\u001B[0m\n\u001B[0;31m    find_content(\"Personal\")\u001B[0m\n\u001B[0m                            ^\u001B[0m\n\u001B[0;31mIndentationError\u001B[0m\u001B[0;31m:\u001B[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# 6\n",
    "def find_content(word: str):\n",
    "    site = soup.find(id=\"mw-content-text\")\n",
    "\n",
    "    for k in toc_dict.keys():\n",
    "        if word in k:\n",
    "            found = toc_dict.get(k)\n",
    "            print(f\"{url}{found}\")\n",
    "            found = found[1:]\n",
    "            element = soup.find(id=found)\n",
    "            text = \"\"\n",
    "            for tag in element.find_all_next():\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "find_content(\"Personal\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Part 2\n",
    "##### 40 min\n",
    "1. Using regex find out how many times 'Turing' is used in the article\n",
    "9. Regex: Find all the sentences that has a year in them (sentense defined by: starting at \\n or dot or comma and ending at dot or comma."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "turing = re.compile(r\"Turing\")\n",
    "re_year = re.compile(r\"[.,\\n]*\\d{4,4}[$.,\\n]\")\n",
    "found_turner = soup.find_all(text=turing)\n",
    "found_year = soup.find_all(text=re_year)\n",
    "\n",
    "for i in found_year:\n",
    "    print(found_year)\n",
    "\n",
    "#print(f\"Turner: {len(found_turner)}\")\n",
    "print(f\"Sentences: {len(found_year)}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}